{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482e0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import os\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23306a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433845 values\n"
     ]
    }
   ],
   "source": [
    "body_part = \"head\"\n",
    "file_names = ['./data/training_data/head_data_1.log',\n",
    "             './data/training_data/head_data_2.log',\n",
    "             './data/training_data/head_data_3.log',\n",
    "             './data/training_data/head_data_4.log',\n",
    "             './data/training_data/head_data_5.log',\n",
    "             './data/training_data/head_data_6.log']\n",
    "\n",
    "# body_part = \"shoulder_right\"\n",
    "# file_names = [\n",
    "#              './data/training_data/shoulder_right_data_6.log',\n",
    "#              './data/training_data/shoulder_right_data_7.log',\n",
    "#              './data/training_data/shoulder_right_data_8.log',\n",
    "#              './data/training_data/shoulder_right_data_9.log',\n",
    "#              './data/training_data/shoulder_right_data_14.log',\n",
    "#              './data/training_data/shoulder_right_data_15.log',\n",
    "#              './data/training_data/shoulder_right_data_16.log',\n",
    "#              './data/training_data/shoulder_right_data_17.log']\n",
    "\n",
    "# body_part = \"shoulder_left\"\n",
    "# file_names = ['./data/training_data/shoulder_left_data_1.log',\n",
    "#               './data/training_data/shoulder_left_data_2.log',\n",
    "#               './data/training_data/shoulder_left_data_3.log']\n",
    "\n",
    "dataset = [pd.read_csv(f, delim_whitespace=True, header=0) for f in file_names]\n",
    "dataset = [data[(np.abs(stats.zscore(data[[\"roll\", \"pitch\", \"yaw\"]])) < 2.75).all(axis=1)] for data in dataset]\n",
    "dataset_len = [len(data) for data in dataset]\n",
    "dataset = pd.concat(dataset)\n",
    "\n",
    "print('%d values'%(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96519df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[102093, 8746, 38589, 219455, 18399, 46563]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026edec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433843 values after filtering outliers\n",
      "max euler 1.0645041825449684\n",
      "min euler -0.9293592614230198\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.values[1:len(dataset)-1,0:]\n",
    "# np.random.shuffle(dataset)\n",
    "\n",
    "dataset = dataset[abs(dataset[:,12])!=0.0,:]\n",
    "dataset = dataset[abs(dataset[:,13])!=0.0,:]\n",
    "dataset = dataset[abs(dataset[:,14])!=0.0,:]\n",
    "print('%d values after filtering outliers'%(len(dataset)))\n",
    "\n",
    "euler_set = dataset[:, 12:15]\n",
    "print('max euler ' + str(np.amax(euler_set)))\n",
    "print('min euler ' + str(np.amin(euler_set)))\n",
    "sensors_set = dataset[:, :12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a18c2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_cos_set = np.hstack([np.sin(euler_set), np.cos(euler_set)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29089bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_scaler = MinMaxScaler(feature_range=(-1., 1.))\n",
    "sensors_set = sensors_scaler.fit_transform(sensors_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1825d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = 0.8\n",
    "split_idx = int(len(sensors_set)*data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c84d04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102073\n",
      "110799\n",
      "149368\n",
      "368803\n",
      "387182\n",
      "433725\n"
     ]
    }
   ],
   "source": [
    "look_back = 10\n",
    "\n",
    "data_in = []\n",
    "data_out = []\n",
    "\n",
    "start_idx = 0\n",
    "for l in dataset_len:\n",
    "    # Ignore the last batch\n",
    "    for i in range(start_idx, start_idx+l-look_back*2):\n",
    "        data_in.append(sensors_set[i:i+look_back])\n",
    "        data_out.append(sin_cos_set[i+1:i+look_back+1])\n",
    "    print(len(data_in))\n",
    "    start_idx += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1531645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = 0.8\n",
    "data_idx = np.arange(len(data_in))\n",
    "np.random.shuffle(data_idx)\n",
    "split_idx = int(len(data_in)*data_split)\n",
    "\n",
    "train_in = np.array(data_in)[data_idx[:split_idx]]\n",
    "train_out = np.array(data_out)[data_idx[:split_idx]]\n",
    "test_in = np.array(data_in)[data_idx[split_idx:]]\n",
    "test_out = np.array(data_out)[data_idx[split_idx:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd53c828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346980, 10, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_in.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182f02f",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81e0317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/roboy/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from nn_model import NeuralNetworkModel, LSTMNeuralNetworkModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d12ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roboy/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "/home/roboy/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0000: Traing loss 0.34209, Valid loss 0.06837\n",
      "#0010: Traing loss 0.02461, Valid loss 0.02424\n",
      "#0020: Traing loss 0.02335, Valid loss 0.02317\n",
      "#0030: Traing loss 0.01697, Valid loss 0.01687\n",
      "#0040: Traing loss 0.00508, Valid loss 0.00498\n",
      "#0050: Traing loss 0.00471, Valid loss 0.00477\n",
      "#0060: Traing loss 0.00463, Valid loss 0.00475\n",
      "#0070: Traing loss 0.00454, Valid loss 0.00454\n",
      "#0080: Traing loss 0.00449, Valid loss 0.00442\n",
      "#0090: Traing loss 0.00443, Valid loss 0.00437\n",
      "#0100: Traing loss 0.00439, Valid loss 0.00434\n",
      "#0110: Traing loss 0.00430, Valid loss 0.00443\n",
      "#0120: Traing loss 0.00425, Valid loss 0.00424\n",
      "#0130: Traing loss 0.00420, Valid loss 0.00417\n",
      "#0140: Traing loss 0.00413, Valid loss 0.00416\n",
      "#0150: Traing loss 0.00406, Valid loss 0.00412\n",
      "#0160: Traing loss 0.00400, Valid loss 0.00401\n",
      "#0170: Traing loss 0.00394, Valid loss 0.00397\n",
      "#0180: Traing loss 0.00386, Valid loss 0.00391\n",
      "#0190: Traing loss 0.00384, Valid loss 0.00391\n",
      "#0200: Traing loss 0.00373, Valid loss 0.00379\n",
      "#0210: Traing loss 0.00365, Valid loss 0.00371\n",
      "#0220: Traing loss 0.00361, Valid loss 0.00385\n",
      "#0230: Traing loss 0.00362, Valid loss 0.00365\n",
      "#0240: Traing loss 0.00353, Valid loss 0.00360\n",
      "#0250: Traing loss 0.00342, Valid loss 0.00363\n",
      "#0260: Traing loss 0.00338, Valid loss 0.00345\n",
      "#0270: Traing loss 0.00335, Valid loss 0.00341\n",
      "#0280: Traing loss 0.00326, Valid loss 0.00335\n",
      "#0290: Traing loss 0.00322, Valid loss 0.00334\n",
      "#0300: Traing loss 0.00319, Valid loss 0.00332\n",
      "#0310: Traing loss 0.00316, Valid loss 0.00333\n",
      "#0320: Traing loss 0.00305, Valid loss 0.00321\n",
      "#0330: Traing loss 0.00305, Valid loss 0.00322\n",
      "#0340: Traing loss 0.00301, Valid loss 0.00324\n",
      "#0350: Traing loss 0.00300, Valid loss 0.00330\n",
      "#0360: Traing loss 0.00296, Valid loss 0.00315\n",
      "#0370: Traing loss 0.00292, Valid loss 0.00310\n",
      "#0380: Traing loss 0.00294, Valid loss 0.00304\n",
      "#0390: Traing loss 0.00286, Valid loss 0.00304\n",
      "#0400: Traing loss 0.00279, Valid loss 0.00301\n",
      "#0410: Traing loss 0.00284, Valid loss 0.00321\n",
      "#0420: Traing loss 0.00285, Valid loss 0.00305\n",
      "#0430: Traing loss 0.00276, Valid loss 0.00295\n",
      "#0440: Traing loss 0.00270, Valid loss 0.00294\n",
      "#0450: Traing loss 0.00276, Valid loss 0.00304\n",
      "#0460: Traing loss 0.00275, Valid loss 0.00309\n",
      "#0470: Traing loss 0.00269, Valid loss 0.00293\n",
      "#0480: Traing loss 0.00274, Valid loss 0.00292\n",
      "#0490: Traing loss 0.00272, Valid loss 0.00290\n",
      "#0500: Traing loss 0.00263, Valid loss 0.00292\n",
      "#0510: Traing loss 0.00258, Valid loss 0.00286\n",
      "#0520: Traing loss 0.00260, Valid loss 0.00291\n",
      "#0530: Traing loss 0.00252, Valid loss 0.00292\n",
      "#0540: Traing loss 0.00258, Valid loss 0.00303\n",
      "#0550: Traing loss 0.00252, Valid loss 0.00289\n",
      "#0560: Traing loss 0.00267, Valid loss 0.00289\n",
      "#0570: Traing loss 0.00249, Valid loss 0.00285\n",
      "#0580: Traing loss 0.00248, Valid loss 0.00278\n",
      "#0590: Traing loss 0.00242, Valid loss 0.00273\n",
      "#0600: Traing loss 0.00248, Valid loss 0.00281\n",
      "#0610: Traing loss 0.00245, Valid loss 0.00278\n",
      "#0620: Traing loss 0.00241, Valid loss 0.00283\n",
      "#0630: Traing loss 0.00246, Valid loss 0.00285\n",
      "#0640: Traing loss 0.00238, Valid loss 0.00269\n",
      "#0650: Traing loss 0.00240, Valid loss 0.00275\n",
      "#0660: Traing loss 0.00249, Valid loss 0.00279\n",
      "#0670: Traing loss 0.00231, Valid loss 0.00263\n",
      "#0680: Traing loss 0.00231, Valid loss 0.00270\n",
      "#0690: Traing loss 0.00243, Valid loss 0.00274\n",
      "#0700: Traing loss 0.00240, Valid loss 0.00263\n",
      "#0710: Traing loss 0.00228, Valid loss 0.00259\n",
      "#0720: Traing loss 0.00227, Valid loss 0.00269\n",
      "#0730: Traing loss 0.00228, Valid loss 0.00264\n",
      "#0740: Traing loss 0.00224, Valid loss 0.00254\n",
      "#0750: Traing loss 0.00222, Valid loss 0.00255\n",
      "#0760: Traing loss 0.00224, Valid loss 0.00263\n",
      "#0770: Traing loss 0.00220, Valid loss 0.00255\n",
      "#0780: Traing loss 0.00225, Valid loss 0.00259\n",
      "#0790: Traing loss 0.00219, Valid loss 0.00255\n",
      "#0800: Traing loss 0.00227, Valid loss 0.00248\n",
      "#0810: Traing loss 0.00214, Valid loss 0.00256\n",
      "#0820: Traing loss 0.00216, Valid loss 0.00258\n",
      "#0830: Traing loss 0.00228, Valid loss 0.00266\n",
      "#0840: Traing loss 0.00214, Valid loss 0.00244\n",
      "#0850: Traing loss 0.00215, Valid loss 0.00244\n",
      "#0860: Traing loss 0.00218, Valid loss 0.00253\n",
      "#0870: Traing loss 0.00210, Valid loss 0.00244\n",
      "#0880: Traing loss 0.00213, Valid loss 0.00250\n",
      "#0890: Traing loss 0.00210, Valid loss 0.00244\n",
      "#0900: Traing loss 0.00222, Valid loss 0.00245\n",
      "#0910: Traing loss 0.00205, Valid loss 0.00243\n",
      "#0920: Traing loss 0.00204, Valid loss 0.00236\n",
      "#0930: Traing loss 0.00208, Valid loss 0.00241\n",
      "#0940: Traing loss 0.00210, Valid loss 0.00253\n",
      "#0950: Traing loss 0.00205, Valid loss 0.00246\n",
      "#0960: Traing loss 0.00201, Valid loss 0.00234\n",
      "#0970: Traing loss 0.00202, Valid loss 0.00243\n",
      "#0980: Traing loss 0.00200, Valid loss 0.00240\n",
      "Stop training after 0987 iterations\n"
     ]
    }
   ],
   "source": [
    "model_path = './output/'+body_part+'_lstm'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "model_name = model_path+'/best_model'\n",
    "joblib.dump(sensors_scaler, model_path+'/scaler.pkl') \n",
    "\n",
    "model = LSTMNeuralNetworkModel(name=body_part, hidden_size=100, look_back=look_back)\n",
    "# model = NeuralNetworkModel(name=body_part, hidden_size=100)\n",
    "model.fit(x=train_in, y=train_out, x_val=test_in, y_val=test_out, save_path=model_name, \n",
    "         iteration=1000, patience=100, batch_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
