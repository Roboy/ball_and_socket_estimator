{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482e0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import os\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23306a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388290 values\n"
     ]
    }
   ],
   "source": [
    "# body_part = \"head\"\n",
    "# file_names = ['./data/training_data/head_data_1.log',\n",
    "#              './data/training_data/head_data_2.log',\n",
    "#              './data/training_data/head_data_3.log',\n",
    "#              './data/training_data/head_data_4.log',\n",
    "#              './data/training_data/head_data_5.log',\n",
    "#              './data/training_data/head_data_6.log']\n",
    "\n",
    "# body_part = \"shoulder_right\"\n",
    "# file_names = [\n",
    "#              './data/training_data/shoulder_right_data_6.log',\n",
    "#              './data/training_data/shoulder_right_data_7.log',\n",
    "#              './data/training_data/shoulder_right_data_8.log',\n",
    "#              './data/training_data/shoulder_right_data_9.log',\n",
    "#              './data/training_data/shoulder_right_data_14.log',\n",
    "#              './data/training_data/shoulder_right_data_15.log',\n",
    "#              './data/training_data/shoulder_right_data_16.log',\n",
    "#              './data/training_data/shoulder_right_data_17.log']\n",
    "\n",
    "body_part = \"shoulder_left\"\n",
    "file_names = ['./data/training_data/shoulder_left_data_1.log',\n",
    "              './data/training_data/shoulder_left_data_2.log',\n",
    "              './data/training_data/shoulder_left_data_3.log',\n",
    "             './data/training_data/shoulder_left_data_5.log',\n",
    "             './data/training_data/shoulder_left_data_6.log',\n",
    "             './data/training_data/shoulder_left_data_7.log',\n",
    "             './data/training_data/shoulder_left_data_8.log',\n",
    "             './data/training_data/shoulder_left_data_9.log',\n",
    "             './data/training_data/shoulder_left_data_10.log']\n",
    "\n",
    "dataset = [pd.read_csv(f, delim_whitespace=True, header=0) for f in file_names]\n",
    "dataset = [data[(np.abs(stats.zscore(data[[\"roll\", \"pitch\", \"yaw\"]])) < 2.75).all(axis=1)] for data in dataset]\n",
    "dataset_len = [len(data) for data in dataset]\n",
    "dataset = pd.concat(dataset)\n",
    "\n",
    "print('%d values'%(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96519df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[106932, 13820, 17110, 22581, 188034, 10040, 6016, 9517, 14240]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026edec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388288 values after filtering outliers\n",
      "max euler 1.753607419226561\n",
      "min euler -2.586471863241787\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.values[1:len(dataset)-1,0:]\n",
    "# np.random.shuffle(dataset)\n",
    "\n",
    "dataset = dataset[abs(dataset[:,12])!=0.0,:]\n",
    "dataset = dataset[abs(dataset[:,13])!=0.0,:]\n",
    "dataset = dataset[abs(dataset[:,14])!=0.0,:]\n",
    "print('%d values after filtering outliers'%(len(dataset)))\n",
    "\n",
    "euler_set = dataset[:, 12:15]\n",
    "print('max euler ' + str(np.amax(euler_set)))\n",
    "print('min euler ' + str(np.amin(euler_set)))\n",
    "sensors_set = dataset[:, :12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a18c2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_cos_set = np.hstack([np.sin(euler_set), np.cos(euler_set)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29089bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_scaler = MinMaxScaler(feature_range=(-1., 1.))\n",
    "sensors_set = sensors_scaler.fit_transform(sensors_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1825d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = 0.8\n",
    "split_idx = int(len(sensors_set)*data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c84d04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106912\n",
      "120712\n",
      "137802\n",
      "160363\n",
      "348377\n",
      "358397\n",
      "364393\n",
      "373890\n",
      "388110\n"
     ]
    }
   ],
   "source": [
    "look_back = 10\n",
    "\n",
    "data_in = []\n",
    "data_out = []\n",
    "\n",
    "start_idx = 0\n",
    "for l in dataset_len:\n",
    "    # Ignore the last batch\n",
    "    for i in range(start_idx, start_idx+l-look_back*2):\n",
    "        data_in.append(sensors_set[i:i+look_back])\n",
    "        data_out.append(sin_cos_set[i+1:i+look_back+1])\n",
    "    print(len(data_in))\n",
    "    start_idx += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1531645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = 0.8\n",
    "data_idx = np.arange(len(data_in))\n",
    "np.random.shuffle(data_idx)\n",
    "split_idx = int(len(data_in)*data_split)\n",
    "\n",
    "train_in = np.array(data_in)[data_idx[:split_idx]]\n",
    "train_out = np.array(data_out)[data_idx[:split_idx]]\n",
    "test_in = np.array(data_in)[data_idx[split_idx:]]\n",
    "test_out = np.array(data_out)[data_idx[split_idx:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd53c828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310488, 10, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_in.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182f02f",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81e0317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/roboy/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from nn_model import NeuralNetworkModel, LSTMNeuralNetworkModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d12ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roboy/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "/home/roboy/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0000: Traing loss 0.48636, Valid loss 0.13181\n",
      "#0010: Traing loss 0.01379, Valid loss 0.01308\n",
      "#0020: Traing loss 0.00883, Valid loss 0.00851\n",
      "#0030: Traing loss 0.00749, Valid loss 0.00740\n",
      "#0040: Traing loss 0.00694, Valid loss 0.00682\n",
      "#0050: Traing loss 0.00657, Valid loss 0.00658\n",
      "#0060: Traing loss 0.00630, Valid loss 0.00624\n",
      "#0070: Traing loss 0.00609, Valid loss 0.00603\n",
      "#0080: Traing loss 0.00591, Valid loss 0.00588\n",
      "#0090: Traing loss 0.00575, Valid loss 0.00587\n",
      "#0100: Traing loss 0.00564, Valid loss 0.00562\n",
      "#0110: Traing loss 0.00550, Valid loss 0.00547\n",
      "#0120: Traing loss 0.00539, Valid loss 0.00542\n",
      "#0130: Traing loss 0.00525, Valid loss 0.00524\n",
      "#0140: Traing loss 0.00516, Valid loss 0.00533\n",
      "#0150: Traing loss 0.00508, Valid loss 0.00504\n",
      "#0160: Traing loss 0.00500, Valid loss 0.00503\n",
      "#0170: Traing loss 0.00494, Valid loss 0.00494\n",
      "#0180: Traing loss 0.00484, Valid loss 0.00481\n",
      "#0190: Traing loss 0.00475, Valid loss 0.00469\n",
      "#0200: Traing loss 0.00469, Valid loss 0.00465\n",
      "#0210: Traing loss 0.00461, Valid loss 0.00464\n",
      "#0220: Traing loss 0.00453, Valid loss 0.00460\n",
      "#0230: Traing loss 0.00444, Valid loss 0.00448\n",
      "#0240: Traing loss 0.00438, Valid loss 0.00443\n",
      "#0250: Traing loss 0.00433, Valid loss 0.00441\n",
      "#0260: Traing loss 0.00425, Valid loss 0.00429\n",
      "#0270: Traing loss 0.00420, Valid loss 0.00428\n",
      "#0280: Traing loss 0.00416, Valid loss 0.00429\n",
      "#0290: Traing loss 0.00409, Valid loss 0.00408\n",
      "#0300: Traing loss 0.00405, Valid loss 0.00415\n",
      "#0310: Traing loss 0.00396, Valid loss 0.00412\n",
      "#0320: Traing loss 0.00392, Valid loss 0.00400\n",
      "#0330: Traing loss 0.00387, Valid loss 0.00408\n",
      "#0340: Traing loss 0.00382, Valid loss 0.00385\n",
      "#0350: Traing loss 0.00377, Valid loss 0.00384\n",
      "#0360: Traing loss 0.00374, Valid loss 0.00378\n",
      "#0370: Traing loss 0.00369, Valid loss 0.00375\n",
      "#0380: Traing loss 0.00364, Valid loss 0.00384\n",
      "#0390: Traing loss 0.00360, Valid loss 0.00370\n",
      "#0400: Traing loss 0.00354, Valid loss 0.00367\n",
      "#0410: Traing loss 0.00351, Valid loss 0.00365\n",
      "#0420: Traing loss 0.00351, Valid loss 0.00371\n",
      "#0430: Traing loss 0.00343, Valid loss 0.00366\n",
      "#0440: Traing loss 0.00343, Valid loss 0.00352\n",
      "#0450: Traing loss 0.00339, Valid loss 0.00352\n",
      "#0460: Traing loss 0.00338, Valid loss 0.00355\n",
      "#0470: Traing loss 0.00330, Valid loss 0.00351\n",
      "#0480: Traing loss 0.00330, Valid loss 0.00345\n",
      "#0490: Traing loss 0.00326, Valid loss 0.00339\n"
     ]
    }
   ],
   "source": [
    "model_path = './output/'+body_part+'_lstm__new__'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "model_name = model_path+'/best_model'\n",
    "joblib.dump(sensors_scaler, model_path+'/scaler.pkl') \n",
    "\n",
    "model = LSTMNeuralNetworkModel(name=body_part, hidden_size=100, look_back=look_back)\n",
    "# model = NeuralNetworkModel(name=body_part, hidden_size=100)\n",
    "model.fit(x=train_in, y=train_out, x_val=test_in, y_val=test_out, save_path=model_name, \n",
    "         iteration=500, patience=100, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b456ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0000: Traing loss 0.00322, Valid loss 0.00333\n",
      "#0010: Traing loss 0.00322, Valid loss 0.00340\n",
      "#0020: Traing loss 0.00316, Valid loss 0.00330\n",
      "#0030: Traing loss 0.00312, Valid loss 0.00324\n",
      "#0040: Traing loss 0.00313, Valid loss 0.00323\n",
      "#0050: Traing loss 0.00315, Valid loss 0.00321\n",
      "#0060: Traing loss 0.00306, Valid loss 0.00323\n",
      "#0070: Traing loss 0.00305, Valid loss 0.00316\n",
      "#0080: Traing loss 0.00303, Valid loss 0.00314\n",
      "#0090: Traing loss 0.00301, Valid loss 0.00322\n",
      "#0100: Traing loss 0.00297, Valid loss 0.00312\n",
      "#0110: Traing loss 0.00296, Valid loss 0.00318\n",
      "#0120: Traing loss 0.00295, Valid loss 0.00323\n",
      "#0130: Traing loss 0.00293, Valid loss 0.00307\n",
      "#0140: Traing loss 0.00292, Valid loss 0.00305\n",
      "#0150: Traing loss 0.00289, Valid loss 0.00307\n",
      "#0160: Traing loss 0.00292, Valid loss 0.00302\n",
      "#0170: Traing loss 0.00282, Valid loss 0.00293\n",
      "#0180: Traing loss 0.00281, Valid loss 0.00295\n",
      "#0190: Traing loss 0.00280, Valid loss 0.00295\n",
      "#0200: Traing loss 0.00283, Valid loss 0.00299\n",
      "#0210: Traing loss 0.00278, Valid loss 0.00292\n",
      "#0220: Traing loss 0.00282, Valid loss 0.00306\n",
      "#0230: Traing loss 0.00278, Valid loss 0.00307\n",
      "#0240: Traing loss 0.00274, Valid loss 0.00289\n",
      "#0250: Traing loss 0.00276, Valid loss 0.00287\n",
      "#0260: Traing loss 0.00273, Valid loss 0.00289\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6e3fa9ba80a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(x=train_in, y=train_out, x_val=test_in, y_val=test_out, save_path=model_name, \n\u001b[0m\u001b[1;32m      2\u001b[0m          iteration=500, patience=100, batch_size=1000)\n",
      "\u001b[0;32m~/roboy3/src/ball_in_socket_estimator/python/nn_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, x_val, y_val, save_path, iteration, patience, batch_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 }\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mtraining_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_train_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1369\u001b[0m                            run_metadata)\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1360\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1449\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1450\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1451\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=train_in, y=train_out, x_val=test_in, y_val=test_out, save_path=model_name, \n",
    "         iteration=500, patience=100, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee70fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
